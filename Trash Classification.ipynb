{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/Sulbae/E-Waste-Classification/raw/main/E-Waste_Dataset.zip'\n",
    "path_zip = 'Waste_Dataset.zip'\n",
    "extracted_path = 'waste_dataset'\n",
    "\n",
    "urllib.request.urlretrieve(url, path_zip)\n",
    "\n",
    "with zipfile.ZipFile(path_zip, 'r') as zip_data:\n",
    "    zip_data.extractall(extracted_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(extracted_path, r'D:\\2. Self Dev & Goals\\3. Upgrading Skills\\Dicoding\\1. ML - Intermediate Level\\Project 2_Image Class\\Image_Classification\\waste_dataset\\Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Path Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "class_list = os.listdir(data_dir)\n",
    "\n",
    "for classes in class_list:\n",
    "    class_path = os.path.join(data_dir, classes)\n",
    "    if os.path.isdir(class_path):\n",
    "        file_list = os.listdir(class_path)\n",
    "        for file in file_list:\n",
    "            f_path = os.path.join(class_path, file)\n",
    "            file_paths.append(f_path)\n",
    "            labels.append(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          file_paths   labels\n",
      "0  D:\\2. Self Dev & Goals\\3. Upgrading Skills\\Dic...  Battery\n",
      "1  D:\\2. Self Dev & Goals\\3. Upgrading Skills\\Dic...  Battery\n",
      "2  D:\\2. Self Dev & Goals\\3. Upgrading Skills\\Dic...  Battery\n",
      "3  D:\\2. Self Dev & Goals\\3. Upgrading Skills\\Dic...  Battery\n",
      "4  D:\\2. Self Dev & Goals\\3. Upgrading Skills\\Dic...  Battery\n",
      "labels\n",
      "Battery            300\n",
      "Keyboard           300\n",
      "Microwave          300\n",
      "Mobile             300\n",
      "Mouse              300\n",
      "PCB                300\n",
      "Player             300\n",
      "Printer            300\n",
      "Television         300\n",
      "Washing Machine    300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Path Checking\n",
    "\n",
    "F_series = pd.Series(file_paths, name='file_paths')\n",
    "L_series = pd.Series(labels, name='labels')\n",
    "\n",
    "data_df = pd.concat([F_series, L_series], axis=1)\n",
    "\n",
    "print(data_df.head())\n",
    "print(data_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8 \n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data_df, test_size=test_size, shuffle=True, random_state=42)\n",
    "\n",
    "print('train_set length:', len(train_set), 'test_set length:', len(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarisasi\n",
    "height = 150\n",
    "width = 150\n",
    "channels = 3\n",
    "batch_size = 128\n",
    "img_shape = (height, width, channels)\n",
    "img_size = (height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale= 1./255.,\n",
    "    rotation_range= 30,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True,\n",
    "    fill_mode= 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "train_gen = datagen.flow_from_dataframe(train_set,\n",
    "                                        x_col='file_paths',\n",
    "                                        y_col= 'labels',\n",
    "                                        target_size= img_size,\n",
    "                                        class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb',\n",
    "                                        shuffle= True,\n",
    "                                        batch_size= batch_size\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test_gen = datagen.flow_from_dataframe(test_set,\n",
    "                                        x_col='file_paths',\n",
    "                                        y_col= 'labels',\n",
    "                                        target_size= img_size,\n",
    "                                        class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb',\n",
    "                                        shuffle= True,\n",
    "                                        batch_size= batch_size\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = list(train_gen.class_indices.keys())\n",
    "print(train_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(generator):\n",
    "    images, labels = next(generator)\n",
    "    plt.figure(figsize= (20, 20))\n",
    "    for i in range(min(len(labels), 20)):\n",
    "        plt.subplot(5, 4, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        index = np.argmax(labels[i])\n",
    "        class_name = train_categories[index]\n",
    "        plt.title(class_name, color='blue', fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisiin extractor dan compile model\n",
    "base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block_15_project_BN').output)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    extractor,  # Feature extractor\n",
    "    Conv2D(filters=32, padding='same', kernel_size=3, activation='relu'),\n",
    "    MaxPooling2D(pool_size=2, strides=2),\n",
    "    Conv2D(filters=64, padding='same', kernel_size=3, activation='relu'),\n",
    "    MaxPooling2D(pool_size=2, strides=2),\n",
    "    Dropout(rate=0.5),\n",
    "    Flatten(),\n",
    "    Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Call build() method to build the model\n",
    "model.build((None, 224, 224, 3))\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit(train_gen, epochs=20, validation_data=valid_gen, callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue', linestyle='-')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange', linestyle='--')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', color='green', linestyle='-')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red', linestyle='--')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
